{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e877ee",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline\n",
    "\n",
    "Now that we have experience preparing data for input to machine learning libraries, the next step will be to train, tune, and test a model.  You will perform all three of these steps in this hands-on activity.\n",
    "\n",
    "The assignment consists of the following steps:\n",
    "\n",
    "1. Load two datasets and prepare their representations and labels for model input. \n",
    "2. Split the data into training and testing.\n",
    "3. Select a model, and identify the parameters to tune.\n",
    "4. Tune the model.\n",
    "5. Evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c5dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"scapy.runtime\").setLevel(logging.ERROR)\n",
    "\n",
    "from netml.pparser.parser import PCAP\n",
    "from netml.utils.tool import dump_data, load_data\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838feb39",
   "metadata": {},
   "source": [
    "## Convert the Packet Capture Into Flows\n",
    "\n",
    "1. Load the two packet captures for HTTP requests and Log4j scan, \n",
    "2. convert them into traffic flows, \n",
    "3. generate features from the flow,  \n",
    "4. label the traffic,\n",
    "5. normalize your labeled features into a 2D matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0dc999",
   "metadata": {},
   "source": [
    "## Evaluating a Machine Learning Model\n",
    "\n",
    "The goal of supervised learning is to train a model that takes examples and predicts labels for these examples that are as close as possible to the actual labels. For instance, in this example above, a model might take features from a traffic trace and predict whether the traffic constitutes regular web traffic or a scan.\n",
    "\n",
    "How do you measure whether the model is succeeding if you don't know the true labels for new observations? The way to solve this problem is to test the performance of the trained algorithm on additional data that it has never seen, but for which you already know the correct labels. \n",
    "\n",
    "This requires that you train the algorithm using only a portion of the entire labeled dataset (the **training set**) and withold the rest of the labeled data (the **test set**) for testing how well the model generalizes to new information. \n",
    "\n",
    "To evaluate the model, we will need to split the data into train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1540bf92",
   "metadata": {},
   "source": [
    "### Split into Training and Test Sets\n",
    "\n",
    "Split your data into a training and test set using scikit-learn. A common split is to train on 80% of your data, while withholding 20% of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bcd475",
   "metadata": {},
   "source": [
    "### Training Your Model\n",
    "\n",
    "Now that you have split your data into training and testing sets, you are ready to train and evaluate a model. \n",
    "\n",
    "Import a machine learning model of your choice, use your training set to train the model, and use the test set to evaluate it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f78849",
   "metadata": {},
   "source": [
    "### Test Your Trained Model\n",
    "\n",
    "You can now evaluate how well your trained model works.  There are several valuable ways to visualize your results. You might use techniques such as a confusion matrix, or a receiver operating characteristic (ROC) curve. Below we will gain some experience plotting both of those.  This [documentation](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_display_object_visualization.html) may help you with plotting these results.\n",
    "\n",
    "#### Confusion Matrix \n",
    "\n",
    "A confusion matrix is a one way to understand errors of different types. We can see a lot of examples off diagonal, suggesting a fair number of incorrect answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f2d85",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic\n",
    "\n",
    "Some models can output different classes based on a threshold that is set for the decision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea3191",
   "metadata": {},
   "source": [
    "### Area Under the Curve (AUC)\n",
    "\n",
    "From the ROC above, you can also compute a metric called the area under the curve (AUC). Visually, this is the area under the curve that you just plotted. You could see, intuitively, that the \"best\" performance should yield an AUC of 1, and the worst performance would yield an AUC closer to 0.5.\n",
    "\n",
    "Scikit learn also has a function for computing AUC.  Compute the area under the curve."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
