<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Chapter 5: Supervised Learning &mdash; Machine Learning for Networking Version 0.1 documentation</title><link rel="stylesheet" href="../static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../static/css/rtd_theme_mods.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../static/nbsphinx-code-cells.css" type="text/css" />
    <link rel="shortcut icon" href="../static/bridge.ico"/>
  <!--[if lt IE 9]>
    <script src="../static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
        <script src="../static/jquery.js"></script>
        <script src="../static/underscore.js"></script>
        <script src="../static/doctools.js"></script>
        <script src="../static/language_data.js"></script>
        <script src="https://www.googletagmanager.com/gtag/js?id=G-QLSP3FJWGT"></script>
        <script >
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-QLSP3FJWGT');
</script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../static/js/theme.js"></script>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Chapter 6: Unsupervised Learning" href="unsupervised.html" />
    <link rel="prev" title="Chapter 4: Machine Learning Pipeline" href="pipeline.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Machine Learning for Networking
          </a>
              <div class="version">
                Version 0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Chapter 1:  Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="motivation.html">Chapter 2: Motivating Problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="measurement.html">Chapter 3: Network Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Chapter 4: Machine Learning Pipeline</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Chapter 5: Supervised Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#non-parametric-models">Non-Parametric Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#k-nearest-neighbors">K Nearest Neighbors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#linear-models">Linear Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#linear-regression">Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="#regularization">Regularization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#polynomial-regression-basis-expansion">Polynomial Regression (Basis Expansion)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#logistic-regression">Logistic Regression</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#support-vector-machines">Support Vector Machines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#max-margin-classifiers">Max-Margin Classifiers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-and-prediction">Training and Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#kernel-methods">Kernel Methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#probabilistic-models">Probabilistic Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#naive-bayes">Naive Bayes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#expectation-maximization">Expectation Maximization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#decision-trees">Decision Trees</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#training">Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parameter-tuning">Parameter Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#benefits-and-drawbacks">Benefits and Drawbacks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#ensemble-methods">Ensemble Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#voting">Voting</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bagging-pasting">Bagging &amp; Pasting</a></li>
<li class="toctree-l3"><a class="reference internal" href="#random-forests">Random Forests</a></li>
<li class="toctree-l3"><a class="reference internal" href="#boosting">Boosting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deep-learning">Deep Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#multi-layer-perceptron">Multi-Layer Perceptron</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convolutional-neural-networks">Convolutional Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#recurrent-neural-networks">Recurrent Neural Networks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="unsupervised.html">Chapter 6: Unsupervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm.html">Chapter 7: Large Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="reinforcement.html">Chapter 8: Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="automation.html">Chapter 9:  Deployment Considerations</a></li>
<li class="toctree-l1"><a class="reference internal" href="future.html">Chapter 10:  Looking Ahead</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix.html">Appendix: Activities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../README.html">About The Book</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">About The Authors</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Machine Learning for Networking</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Chapter 5: Supervised Learning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/text/supervised.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul><div class="rst-breadcrumbs-buttons" role="navigation" aria-label="Sequential page navigation">
        <a href="pipeline.html" class="btn btn-neutral float-left" title="Chapter 4: Machine Learning Pipeline" accesskey="p"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="unsupervised.html" class="btn btn-neutral float-right" title="Chapter 6: Unsupervised Learning" accesskey="n">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
  </div>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="chapter-5-supervised-learning">
<h1>Chapter 5: Supervised Learning<a class="headerlink" href="#chapter-5-supervised-learning" title="Permalink to this headline">¶</a></h1>
<p>In this chapter, we will discuss <em>supervised learning</em>, the process by which a
machine learning model can learn from labeled data (sometimes called labeled
examples). Supervised learning requires having access to one or more <em>labeled
datasets</em>—data that has not only the features, but also an associated label
for each data point. For example, in the case of malware classification, the
features might include metrics from the network traffic (e.g., bytes per
second, packets per second, number of IP addresses contacted), and the labels
could be whether the traffic is being generated by a malicious software
software program (“malware”).</p>
<p>In this chapter, we will describe a variety of supervised learning models,
using examples from networking as an illustrative guide. We do not assume
you’ve seen these models before, and so readers who want to get basic
intuition behind different models and how they can be applied in different
network settings should find this chapter illuminating.  Readers who are
already familiar with these models may also find the discussion helpful, as
the examples in the chapter present cases where particular models or types of
models are suited to different classification problems, as well as cases in
the networking domain where these models have been successfully applied.</p>
<p>We organize the discussion of supervised learning in this chapter into the following
categories:</p>
<ol class="arabic simple">
<li><p>non-parametric models (i.e., models where the size of the model grows with the size of the dataset);</p></li>
<li><p>linear models (i.e., models based on a linear prediction function, including possible basis expansion);</p></li>
<li><p>tree-based models;</p></li>
<li><p>ensemble methods (i.e., models that make predictions by combining the predictions of simpler models); and</p></li>
<li><p>deep learning models (i.e., those that can also learn representations of the data).</p></li>
</ol>
<div class="section" id="non-parametric-models">
<h2>Non-Parametric Models<a class="headerlink" href="#non-parametric-models" title="Permalink to this headline">¶</a></h2>
<p>Non-parametric models grow as the size of the dataset grows. Perhaps the most
well-known and widely used non-parametric model is k-nearest neighbors (kNN). We
describe this model below as well as examples where kNN has been used in
networking. We also provide examples for you to try.</p>
<div class="section" id="k-nearest-neighbors">
<h3>K Nearest Neighbors<a class="headerlink" href="#k-nearest-neighbors" title="Permalink to this headline">¶</a></h3>
<p>With K-nearest neighbors, the model has training data, and when trying to
predict a label for a new example, the model predicts the most common label
(classification) or mean (regression) of the k closest examples in the
training data. The model can vary based on the distance function to use to
define “closest” (there are many options), but ultimately, k-nearest neighbors
boils down to finding the closest training examples and predicting their mean
or their mode.</p>
<p>Training a k-nearest neighbors model is simple and efficient: there is nothing
to do other than store the training data in a data structure, such as a
KD-tree, that makes it easy to compare distances between a data point and
observations in the training data. All of the work and computational effort
thus occurs during prediction, where these distances are computed.  The
choice of k is a hyperparameter that can be selected using a standard tuning
approach, such as a line search, along with a validation set.</p>
<p>Because kNN is sometimes impractical (e.g., storing the training set may be
prohibitive, inference time can be large), the model is often used as a
baseline to compare model performance against other more practical models.
kNN is relatively easy to train and optimize, but the computation performance
is poor if the training set has many examples—and gets worse as the training
set grows.  Nonetheless, kNN is often used as a baseline for comparing against
other models.</p>
<p><strong>kNN example here</strong></p>
<p>Because kNN operates by distance computations in a multi-dimensional space,
the model works best when features are standardized to have zero mean and unit
variance. Otherwise, the closest examples may be overwhelmed by one feature
that just happens to have values in smaller units.</p>
<p>Unfortunately, kNN also scales poorly with the number of features in each
example (i.e., the dimensionality of the feature set). Many functions that can
be used to compute distance between vectors don’t work very well in high
dimensions, because in higher dimensional spaces, everything starts to be far
away from everything else. Even if two examples happen to be close to each
other on one dimension, the fact that there’s so many dimensions in the data
set means that they’re likely to be far away on others. As you’re adding the
distances along each dimension or taking the square of the distances along
each dimension, those distances can start to blow up. This phenomenon called
the curse of dimensionality.</p>
<p>You may sometimes try to address this by using some different distance
functions that are tailored for different types of data, but generally, this
so-called “curse of dimensionality” is just a problem for geometric models
that rely on vector similarity or vector distance.</p>
<p>Despite their simplicity, kNN models have been successfully used in various
contexts to perform basic classification tasks using network data. Examples
include: (1) positioning and geolocation; (2) website or device
fingerprinting; and (3) attack classification and detection (e.g., DDoS
detection). Such classifiers are common in research papers, particularly as a
baseline approach or model—or in attack papers where the attack, such as
website fingerprinting, need not be efficient (e.g., if it can be performed
offline, or simply to demonstrate feasibility of an attack). In practice,
other models are typically more common, particularly due to the computational
requirements that can make kNN inefficient in practice.</p>
</div>
</div>
<div class="section" id="linear-models">
<h2>Linear Models<a class="headerlink" href="#linear-models" title="Permalink to this headline">¶</a></h2>
<p>Some prediction problems are well suited to linear models (or simple
polynomial expansions of linear models). In the case of regression (predicting
a continuous target variable), linear regression may be appropriate. In the
case of</p>
<div class="section" id="linear-regression">
<h3>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">¶</a></h3>
<p>Linear regression is one of the simplest supervised models.</p>
<p>Imagine that each data point x has N+1 features
<span class="math notranslate nohighlight">\(\mathbf{x} = [1, x_1, ..., x_N]\)</span>.</p>
<p>A linear regression model trained on this data will have N <em>weight</em> parameters w and a single <em>bias</em> parameter b:
<span class="math notranslate nohighlight">\(\mathbf{w} = [b, w_1, ..., w_N]\)</span>
The model predicts labels as the linear combination of a data point’s features weighted by the model parameters
<span class="math notranslate nohighlight">\(\hat{y} = b + w_1x_1 + ... + w_Nx_N\)</span>
This can be simplified as the dot product of the data point and the model parameters
<span class="math notranslate nohighlight">\(\hat{y} = \mathbf{x} \cdot \mathbf{w}\)</span>
If predicting labels for an entire dataset X, this can be written as the inner
product of the weights with the matrix containing all data points.
<span class="math notranslate nohighlight">\(\mathbf{\hat{y}} = \mathbf{w}^T\mathbf{X}\)</span></p>
<p>This is essentially the equation for a line (<span class="math notranslate nohighlight">\(y = mx + b\)</span>) generalized to more dimensions, where the “slope” of the line is the weight parameters and the “intercept” of the line is the bias parameter.</p>
<div class="sidebar">
<p class="sidebar-title">Activity: Linear Regression</p>
<p>The <a class="reference internal" href="appendix.html#appendix-linear-regression"><span class="std std-ref">Appendix</span></a> provides an activity to
train and evaluate a linear regression model to predict various
characteristics of network traffic from input features (e.g., predicting
flow size from flow duration).</p>
</div>
<p>Training a linear regression model involves choosing the weight and bias parameters to minimize the error between the predicted labels and the actual labels for the training set.
There are many error functions that can be used for this training minimization. A common choice, the mean-square error, is also convenient for training:
<span class="math notranslate nohighlight">\(Error = \frac{1}{m} \sum^{m}_{i=1}(\mathbf{w}^T\mathbf{x} - y)^2\)</span></p>
<p>We can use either a closed-form solution or gradient descent to find values of w that minimize this error across the examples x in the training set.</p>
</div>
<div class="section" id="regularization">
<h3>Regularization<a class="headerlink" href="#regularization" title="Permalink to this headline">¶</a></h3>
<p><em>Ridge Regression</em> is just linear regression with the L2 norm of the
parameters added to the error function. This weight of this term is controlled
with a hyperparameter that allows you to tune the relative emphasis given to
the simplicity of the model (L2 penalty) versus the fit of the model. If you
tune this hyperparameter up quite high, the gradient desceent is really
incentivised to keep the parameter values low in magnitude and the model
simply. If you tune this hyperparameter low, it will incentivize the algorithm
to closely fit the training data.</p>
<p><em>Lasso Regression</em> is just linear regression with the L1 norm of the
parameters added to the error function.  Instead of using the Euclidean
magnitude of the parameter vector as the penalty, you use the sum of the
absolute values of the parameters.  A benefit of using the L1 norm is that it
can push the values of the parameters that aren’t particularly important to 0.
This means that you could even decide to take out those features altogether
and further simplify your model.  Unfortunately Lasso regression gradients can
start to act erratically if there are lots of correlations between features. So
you can get into a situation where as you get closer to the minimum using
gradient descent, your updates start to bounce around rather than settling
into the final value.</p>
<p>To get the benefits of both Lasso and ridge regression, you can combine them
into <em>ElasticNet</em>. The cost function for ElasticNet include the original error
function for linear regression, the term for L1 penalty (from lasso), the term
for L2 penalty (from ridge), and another hyperparamater r that determines how
to mix the two penalties. The more you turn up r, the more it behaves like
lasso. The more you turn down r, the more lit looks like ridge. For the most
part, if your dataset is simple enough for a model to perform well using any
one of these approaches, it will also likely perform well using any of the
others.  Data is generally either amenable to one of these linear models, or
these models just don’t provide enough expressivity and it won’t matter which
regularization option you choose [CITATION NEEDED].</p>
</div>
<div class="section" id="polynomial-regression-basis-expansion">
<h3>Polynomial Regression (Basis Expansion)<a class="headerlink" href="#polynomial-regression-basis-expansion" title="Permalink to this headline">¶</a></h3>
<p>Polynomial regression involves preprocessing the features in your dataset to
include polynomial combinations of existing features. For example, you might
add the square of each feature and the all pairwise products of the features.
Then when you train a linear regression, it’s effectively the same as training
a quadratic because you’re doing linear combinations of second degree
combinations of parameters. You could also do this for features that include
all of the third degree combinations of the original features. This would
quickly increase the number of features as you increase the degree of the
polynomials, but you gain the ability to do the same linear regression training
task while modeling higher degree patterns between your features. This will
let you learn curves that aren’t just straight lines [figure]. It will let
you learn a polynomial model of any degree the same process and gradient
descent.</p>
</div>
<div class="section" id="logistic-regression">
<h3>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h3>
<p>Another common form of regression is logistic regression. Logistic regression
performs almost exactly the same process as linear regression, but with one
minor change: Rather than just performing a linear combination of parameters
and features, the output of that linear combination is used as input to a
<em>sigmoid function</em>. Performing this transformation constrains the output
prediction to the [0,1] range, whereby the output of the linear combination is
either very close to 1 or very close to 0 with a region in the center where
that transition happens fairly quickly.  This is useful for doing
classification.</p>
<div class="sidebar">
<p class="sidebar-title">Activity: Logistic Regression</p>
<p>The <a class="reference internal" href="appendix.html#appendix-logistic-regression"><span class="std std-ref">Appendix</span></a> provides an activity to
train and evaluate a simple logistic regression model to predict whether a
packet is a DNS request or response based on its size.</p>
</div>
<p>When performing classification, you want to know whether a data point is in a specific class or not, so by wrapping model output in a sigmoid, you say if the output is &gt;0.5 assume class 1, and if the output is &lt;0.5 assume class 0. In most cases, you’ll already be very close to 1 or 0. Everything else in the training process works the same way, you just compute the gradient of the error function using this as your predictor. When you compute the gradients, you can use the chain rule to computer the partial derivates. The sigmoid function is continuous and differentiable so that’s not a problem. Everything else, all the gradient descent works the same way, just with the exact equation slightly different as a result for the sigmoid. The book chapter concludes by taking the logistic regression and generalizing it top the multi-class case. The generalization of logistic regression is called “softmax regression”, which we will not talk about today. We will get to the softmax function later, especially in deep learning, but this is good for today. We will use some of these things in programming practice on Thursday. We’ll also do a bit about nearest neighbors, which won’t take us very long at the start.</p>
</div>
</div>
<div class="section" id="support-vector-machines">
<h2>Support Vector Machines<a class="headerlink" href="#support-vector-machines" title="Permalink to this headline">¶</a></h2>
<p>If you are trying to perform a binary (or multi-class) classification task with
linearly separable data, the optimal model will consist of a line (or plane, or
hyperplane) that divides the feature space such that all of the examples on one
side of the line are in one class and all of the examples on the other side of
the line (or plane, or hyperplane) are in the other class.  When asked to
predict the class of a new example, you make the prediction based on which side
of the line the example occurs.</p>
<p>SVMs are very common, and they perform very well for small datasets.  A
dataset that is small but contains features that separate well in linear space
may be very amenable to SVMs.  SVMs can produce predictions that are robust to
overfitting and often good at generalizing.  It is also possible to perform
regression with SVMs. To do so, the aim is to fit all of the data within the
margin instead of outside the margin. The decision line (or plane) thus
becomes a regression line.</p>
<div class="section" id="max-margin-classifiers">
<h3>Max-Margin Classifiers<a class="headerlink" href="#max-margin-classifiers" title="Permalink to this headline">¶</a></h3>
<p>The question remains, how do we choose which line or plane to use for this
model? There might be an infinite number of planes that separate the data, how
do you choose the one with the best chance of optimizing prediction accuracy?
Remember that prediction accuracy comes down to how well the model generalizes
to new data outside the training set. The core intuition behind an SVM is that
the best separating line or plane is the one with the most space between
training examples of different classes—the <em>maximum margin</em>, or the “max
margin”.</p>
<p>Training an SVM involves finding that line that maximizes the margin, i.e. the
space separating the line from the training data. The examples end up closest
to this optimal line are called the <em>support vectors</em>.  These are the examples
that determine the position of a line. If you were to collect a lot more
data, but all of that data were to fall on further from the separating line
than the existing support vectors, it wouldn’t change the position of the
line. This makes support vector machines fairly robust to
overfitting because the only data that affects the ultimate position of the
model are those examples closest to these margin boundaries.</p>
</div>
<div class="section" id="training-and-prediction">
<h3>Training and Prediction<a class="headerlink" href="#training-and-prediction" title="Permalink to this headline">¶</a></h3>
<p>The SVM training process involves finding the separating line (or plane) with
the maximum margin. Of course, real datasets are rarely linearly separable, so
we add another variable to the model that allows for some <em>slack</em>, i.e. for
some training examples to fall on the wrong side of the line or plane. The
primary goals of training are to find parameters W and b that minimize the
error between the predictions and the actual values that also maximize the
margin.  This goal can be achieved either with a quadratic programming solver
or with gradient descent, which are typically programmed into the SVM models
in machine learning libraries.  For a linear SVM, the predicted labels y_hat
is a piecewise function based off a linear combination of the features with
weights w and biases b. If that linear combination is less than zero, we
predict class 0. If this linear combination is greater than or equal to zero,
we predict class 1. SHOW FORMULA.  Show how this combines the algebra and the
geometry (sign of dotproduct) to be “above” or “below” the line</p>
<p><em>Regularization</em> is also possible with SVM models: The higher the value of
hyperparameter C, the more importance the model places on getting the
classifications right (i.e. all examples on the correct sides of the margins).
The lower you make C, the less importance the model places on a few incorrect
classifications as it attempts to find the largest marign possible.</p>
<p>Finally, there are multiple ways to use SVMs to perform multiclass
classifcation. A simple approach is one-versus-rest, where if you have N
classes, you train N SVM classifiers, each binary. The first classifier
predicts whether a example is in class 1 or some different class. The second
classifier whether an example is in class 2 or some different class. Each of
those classifiers would give you a different decision line and you’d have to
do a prediction with all of them and decide which prediction was best for that
dataset. Other approaches include one-versus-one.</p>
</div>
<div class="section" id="kernel-methods">
<h3>Kernel Methods<a class="headerlink" href="#kernel-methods" title="Permalink to this headline">¶</a></h3>
<p>Of course, many datasets are not linearly separable. If you have a dataset
that relies on nonlinear interactions between features, a linear SVM is going
to perform poorly. One option, as we saw with polynomial regression, is to
take the existing features and compute polynomial combinations of them.
However, such an expansion can generate in too many features for higher degree
combinations, degrading both performance and model accuracy.</p>
<p>One solution to this problem is to apply the <em>kernel trick</em>, which relies on
the fact that data which isn’t linearly seperable in low dimensions may be
linearly seperable in high dimensions.  Additionally, the SVM training
algorithm can be reformulated (into the <em>dual</em> format) to involve only
similarity metrics between example features, never on the exact values of the
features themselves.  This allows you to use a <em>kernel function</em> in your
model, which computes the distance between examples in a higher-dimensional
space without ever actually having to project those examples to the higher
dimensional space.</p>
<p>SHOW FORMULA OF SVM WITH KERNEL K.</p>
<p>There are many well-studied kernel functions that existing machine learning
libraries provide, each with pros and cons. Nonetheless, they all allow us to
adapt linear SVMs to nonlinear data.</p>
</div>
</div>
<div class="section" id="probabilistic-models">
<h2>Probabilistic Models<a class="headerlink" href="#probabilistic-models" title="Permalink to this headline">¶</a></h2>
<div class="section" id="naive-bayes">
<h3>Naive Bayes<a class="headerlink" href="#naive-bayes" title="Permalink to this headline">¶</a></h3>
<p>Let’s now explore a classifier called the naive Bayes classifier. The naive
Bayes classifier is a type of classification method in a family called kernel
density classification.  Naive Bayes works well on small data sets, it’s
computationally efficient for both training and prediction, and it works well
in a variety of settings.</p>
<p>It typically requires knowing or estimating the probability density of the
feature space from which we’re trying to perform the estimation.  There’s a
notion called an optimal base classifier, where if you knew that the data had
an underlying probability distribution you could formulate an optimal
classifier as follows given a set of observations X, you could pick the Y that
maximizes the posterior probability of observing Y being a particular class
given those observations.  Doing so requires knowing the probability
distributions of the features on which we’re performing this estimation, and
that distribution typically isn’t known, but we can make some assumptions.
What’s commonly done is to select a family of parametric distributions such as
a Gaussian, Bernoulli, or multinomial distribution, and then try to estimate
the parameters of that distribution once we’ve estimated the density of those
features. We can then perform this computation.</p>
<div class="sidebar">
<p class="sidebar-title">Activity: Naive Bayes</p>
<p>The <a class="reference internal" href="appendix.html#appendix-naive-bayes"><span class="std std-ref">Appendix</span></a> provides an activity to train and
evaluate a Naive Bayes classifier to perform spam classification.</p>
</div>
<p>If we’re trying to estimate the probability of Y being a particular value or
class given a set of observations, X, we can use Bayes rule to express that as
the posterior probability of X given Y times the prior probability of Y,
divided by the prior probability of observing those X values.  The naive Bayes
classifier is called a probabilistic classifier, because not only does it make
a class prediction, but it can also predict the likelihood of an observation
being of a particular class, given a set of observations.  The naive Bayes
classifier compares posterior probabilities for each possible class. Because
those probabilities for each observation does not depend on prior probability
of observing the feature values, X, we can drop the denominator and just
compare those numerator values and the class value for y that has the largest
posterior numerator is the predicted class.</p>
<p>The Naive Bayes classifier makes two important assumptions. One is that each
feature X and its corresponding likelihood is independent; that is, there’s no
relationship between the likelihoods of pairs or groups of features. That’s an
assumption that is commonly violated in practice but making this assumption
allows Bayes rule to avoid the curse of dimensionality, where the size of the
required training set often grows exponentially with the number of features in
the model. The second assumption is that for each feature we have to assume
some statistical distribution on the features themselves; in other words, we
have to estimate the kernel density for those features.</p>
<p>There are three common distributions that are used in naive Bayes
classification.  When we have numerical features it’s common to assume a
Gaussian distribution.  If there are categorical features we may use a
Bernoulli distribution. If there are discrete or count features, it’s common to
use a multinomial distribution.  Why do we have to make these statistical
distribution assumptions? If we look at the quantity we’re trying to compute
again it involves computing two quantities: one is the likelihood of Y, or the
prior probability of Y. That’s easy: we just figure out how often each class
occurs in our data set. The second quantity we need to know is the probability
of observing a set of X’s given Y; unless we have an extremely large number of
data points we’re not going to be able to compute this directly, and so we’ll
have to make some assumptions about this particular distribution.</p>
<p>This is where we’re going to make assumptions about the distribution of X, and
specifically the distribution of X conditioned on Y. The second assumption that
we need to make is that those probabilities x given y are independent. In other
words, we can compute the joint probability distribution of those X’s
conditioned on Y by computing the probabilities of each individual feature X
given Y and multiplying them together. This independence assumption greatly
simplifies our computation, so now all we need to do when maximizing this
posterior probability is to compute the following: we choose the value for y
that maximizes the prior probability of observing that value of Y times the
probability of <em>each</em> X_i observation, given that particular class value of Y.</p>
<p>The Naive Bayes classifier has various advantages and disadvantages.  It’s
efficient and scalable: it’s a very simple algorithm based essentially on
counting frequencies of occurrence.  It works on very small data sets. It’s
interpretable: each distribution is estimated as a one-dimensional distribution
because the probabilities of each feature occurring are assumed to be
independent.  Unfortunately, because the Naive Bayes classifier assumes
independence of features, it can’t learn relationships between those features,
which may sometimes be something you want to do in practice.</p>
</div>
<div class="section" id="expectation-maximization">
<h3>Expectation Maximization<a class="headerlink" href="#expectation-maximization" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="decision-trees">
<h2>Decision Trees<a class="headerlink" href="#decision-trees" title="Permalink to this headline">¶</a></h2>
<p>Another way of performing classification or prediction is through performing a
sequence of decisions based on features. Each decision, or step, sub-divides
the data into regions. The goal is to end up with regions that contain only
data points of a single class. Training a decision tree involves making a
sequence of decisions that sub-divide the data into these regions. The model
is called a tree because sequences of decisions are easy to interpret when
depicted as trees.  Once the tree is trained, classification is simple, just
start at the root node and follow the links corresponding to the example you
wish to classify until you reach a leaf node.  Decision trees can also be used
for both classification and regression.</p>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>The goal of training a decision tree is to train a balanced tree that has the
minimal training error, in other words, the minimal difference between the
predicted classes in the training set and the true classes. Balancing the tree
reduces the computational complexity of the prediction process, because it
reduces the maximum number of questions, or splits, that are required to go
from the root of the tree to a leaf.  Unfortunately, the problem of finding the
optimally balanced tree for an arbitrary dataset is NP-complete. In practice,
decision trees rely on iterative algorithms that attempt to optimize for
balance at each step, but do not guarantee that the final tree is as balanced
as possible.</p>
<p>One early decision tree algorithm, the classification and regression tree
algorithm (CART), iteratively selects a feature and finds the boolean
comparison or numeric threshold that all of the examples in the training set as
evenly as possible by number and as uniformly as possible by class. In other
words, the algorithm attempts to choose a feature and a question/threshold that
divides the examples into a left child node and a right child node.  CART is a
greedy algorithm that starts at the root of the tree with all of the training
examples ands repeats the same process with all of the child nodes.  This
continues until each leaf node contains examples from a single class only.</p>
<p>Gini vs. Entropy – probably unnecessary</p>
</div>
<div class="section" id="parameter-tuning">
<h3>Parameter Tuning<a class="headerlink" href="#parameter-tuning" title="Permalink to this headline">¶</a></h3>
<p>Unfortunately, decision trees can be prone to overfitting. As with k-nearest
neighbors, decision trees are nonparametric, which means that they can be
trained to fit the training data perfectly. In the limit, training will result
in a decision tree where every leaf node has examples from only one class.  One
way to limit overfitting with decision trees is to set a maximum depth (or a
minimum split) hyperparameter, which sets the maximum depth of the decision
tree. For any remaining nodes with training examples from more than one class,
the mode of the classes in each node serves as the prediction label.  Another
approach to limiting overfitting is “pruning,” which trains a complete decision
tree and removes splits that causes relatively small decreases in the cost
function.</p>
</div>
<div class="section" id="benefits-and-drawbacks">
<h3>Benefits and Drawbacks<a class="headerlink" href="#benefits-and-drawbacks" title="Permalink to this headline">¶</a></h3>
<p>Decision trees require very little data pre-processing. It doesn’t matter
whether your features are numeric, binary, or nominal, you can still have
conditions in the nodes that work for those classes. For example, one node
could split based on a numeric feature, if packets_per_flow &gt; 1 or == 1.
Another node could split on a nominal feature, “is there an ACK packet in the
flow.o Ypu don’t need to do a one hot encoding, you don’t need to do an ordinal
encoding, you can just feed them right into the tree training algorithm. And
it’ll work no matter what format your features are.</p>
<p>You also don’t need to do any standardization or normalization. as there’s no
notion of this decision tree being geometric, so we don’t need to ensure that
our features are mean zero and variance one.  Decision trees are easily
interpretable by humans. It is possible to look at a decision tree and
understand how it arrived at a particlar prediction.</p>
<p>Decision trees make it easy to compute and compare the relative importance of
features.  We often want to know which features of our dataset are particularly
important for a particular classification. For example, we might want to know
whether the number of packets in a flow is crucially important or peripheral to
our problem. In addition to providing a better understanding of the model, this
can also provide a better understanding of the underlying phenomenon. For
EXAMPLE.</p>
</div>
</div>
<div class="section" id="ensemble-methods">
<h2>Ensemble Methods<a class="headerlink" href="#ensemble-methods" title="Permalink to this headline">¶</a></h2>
<p>If you can train one classifier, why not train more and improve your accuracy by combining their predictions together.  The core idea behind ensemble learning is that if you have a complex phenomenon that you’re trying to understand, you can do a better job of by training a bunch of simpler models with different perspectives instead of a single complex model. This is analogous to the “wisdom of the crowd”.</p>
<div class="section" id="voting">
<h3>Voting<a class="headerlink" href="#voting" title="Permalink to this headline">¶</a></h3>
<p>A “voting classifier” uses several different classes of models (e.g. decision tree, SVM, kNN, etc.) and predicts the majority vote class predicted by each of these models. If the phenomenon is complicated enough, there may not always be one algorithm which does best on new examples. So by having a bunch of algorithms try it, as long as the majority of them do the right thing, you can still give you the right answer in the end.</p>
<p>You can also use the confidence of these models to weight the votes (soft voting classifier).</p>
</div>
<div class="section" id="bagging-pasting">
<h3>Bagging &amp; Pasting<a class="headerlink" href="#bagging-pasting" title="Permalink to this headline">¶</a></h3>
<p>The next approach, bagging and pasting, trains different instances of the same algorithm on different subsets of your training set. Bagging and pasting help to reduce classification variance by sampling from the training set with replacement to create N new training sets that are all slightly different. You train a different model on each set and use the majority vote prediction of all these models.</p>
</div>
<div class="section" id="random-forests">
<h3>Random Forests<a class="headerlink" href="#random-forests" title="Permalink to this headline">¶</a></h3>
<p>Random forests are a particularly important version of bagging, in which you train many small decision trees limited to a maximum depth. (decision trees limited to a single set of child nodes are called decision stumps). Random forests have distinction of being a very, very practical high performance algorithm. Random forests can compete with deep learning algorithms, especially when you’re given datasets that have obvious features. Deep learning really shines when you’re given data that is sort of raw unpasteurised things like images or natural language. But if you’re given a dataset with clear existing features, in many cases a random forest will do as well as a deep learning algorithm on that data. Random forests also have many fewer hyperparameters than a neural network. They are also robust to overfitting.</p>
<div class="sidebar">
<p class="sidebar-title">Activity: Ensemble Methods</p>
<p>The <a class="reference internal" href="appendix.html#appendix-trees-ensembles"><span class="std std-ref">Appendix</span></a> provides an activity to
train and evaluate an ensemble method (i.e., random forest) to predict
certain activities from Internet of things traffic.</p>
</div>
<p>Bagging and random forests are really amenable to parallelization, you can do the sampling. And then you can put each training on a different core, in your data center, train up all in models in parallel</p>
</div>
<div class="section" id="boosting">
<h3>Boosting<a class="headerlink" href="#boosting" title="Permalink to this headline">¶</a></h3>
<p>Another ensemble method callse Boosting has a different motivation than bagging or random forests.  Bagging, pasting, and random forests seek to reduce prediction variance. However, Boosting  attempts to prevent bias errors, which happen when you choose a model that is unable to represent the complexity of the data. In Boosting, you train one algorithm to make a prediction and then you train another algorithm to try to correct the prediction made by the first one. You can repeat this as many times as you like such that by chaining simple models together, you can end up with something which is quite complicated and is able to represent the data very well, even if the data itself is complex. The name comes from the fact that each successive classifier in the sequence is trying to boost the performance of the previous ones.</p>
<p>In gradient boosting, you start off with your training data, you start by training a model, usually a decision tree. This tree gets some of the training set predictions right, and it gets some of them wrong, allowing you to compute a residual between the actual value predicted and the correct value for each examples. Then you train another decision tree to predict the residual of the first tree.  If that prediction is accurate, you can take the prediction of the first tree, correct for the error predicted vy the second tree, and get the right prediction overall. You can also train a third tree to predict the error of the second tree, etc.</p>
<p>Because boosting is inherently sequential, it is not that amenable to parallelized training. Typically, you make each individual classifier very simple and fast to train, so the entire boosted classifier is also efficient.</p>
<p>Another type of boosting, AdaBoost, also uses sequential classifiers that try to improve each other’s performance. The weight given to each example in the training set is increased if the previous classifier got that example incorrect and decreased otherwise. This means that successive classifiers put more effort into correctly predicting examples that were missed by earlier classifiers. Each successive classifier is itself weighted by how well it performs on the entire training set.</p>
<p>There is a proof that AdaBoost combined with any weak learning algorithm, i.e. any classifier that does better than random guessing, will eventually produce a model which perfectly fits your training data. Empirically, this also improves test error as well.</p>
<p>Gradient Boosting…</p>
</div>
</div>
<div class="section" id="deep-learning">
<h2>Deep Learning<a class="headerlink" href="#deep-learning" title="Permalink to this headline">¶</a></h2>
<p>In this section, we will begin our exploration of deep learning by discussing
a particular type of neural network architecture called feed forward neural
networks, which are also sometimes referred to as multi-layer perceptrons. But
before we dive into the technical details of feed forward neural networks, it
is essential to understand the context of deep learning.</p>
<p>Deep learning is a subset of machine learning that is concerned with
representation learning. Unlike traditional machine learning methods, where
the features used as input to the model are manually defined by the designer
of the model, representation learning relies on the algorithm to learn the
best representation of the inputs. An example of a specific type of algorithm
that does this is an autoencoder. The idea behind representation learning is
that the model should learn the best representation for the input, rather than
the designer of the algorithm having to figure out how to represent the inputs
to the model.</p>
<div class="sidebar">
<p class="sidebar-title">Activity: Deep Learning</p>
<p>The <a class="reference internal" href="appendix.html#appendix-deep-learning"><span class="std std-ref">Appendix</span></a> provides an activity to
train and evaluate a deep learning model to predict
attacks from Internet of things devices, and compare the performance of
that model to more conventional models.</p>
</div>
<p>Deep learning takes this concept of representation learning one step further
by introducing many transformations or layers in the model. Hence the name
“deep” learning. The basic unit of deep learning is called a neuron, which
takes a multidimensional input and applies weights to each input feature. The
output of this computation is then passed through an activation function,
which maps the output to 0, 1, or 2. Different shapes of activation functions
can be used for this purpose.</p>
<p>Deep learning is concerned with representation learning and
involves many transformations or layers in the model. A feed forward neural
network is a particular type of neural net architecture that is used in deep
learning. The training process of a neural net is iterative, involving both
forward and backward propagation through the network. The weights of the
neural net are adjusted to reduce loss, and a typical training process might
include hundreds or even thousands of epochs.</p>
<div class="section" id="multi-layer-perceptron">
<h3>Multi-Layer Perceptron<a class="headerlink" href="#multi-layer-perceptron" title="Permalink to this headline">¶</a></h3>
<p>A multi-layer perceptron takes multidimensional input features, applies
weights to those inputs, passes each input feature through a neuron, and
ultimately aggregates the output of the hidden layer to a single neuron that
performs the prediction based on the output of an activation function. The
deep learning training process attempts to find good values for each of these
weights in the network, and each neuron has an activation function. The three
most common shapes of activation functions are the sigmoid function, the
hyperbolic tangent function, and the rectified linear unit function.</p>
<p>Training the weights of a neural net is an iterative process that involves
both forward and backward propagation through the network. Each epoch involves
both backpropagation and forward propagation. In forward propagation, we
evaluate the output against the true value of y and compute a loss or error
function. Backpropagation involves adjusting each of the weights in the neural
net to correct for the resulting error. There is no typical closed-form
optimal solution for the weights. Generally, it is an iterative search
process, and a typical training process might include hundreds or even
thousands of epochs.</p>
</div>
<div class="section" id="convolutional-neural-networks">
<h3>Convolutional Neural Networks<a class="headerlink" href="#convolutional-neural-networks" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="recurrent-neural-networks">
<h3>Recurrent Neural Networks<a class="headerlink" href="#recurrent-neural-networks" title="Permalink to this headline">¶</a></h3>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="pipeline.html" class="btn btn-neutral float-left" title="Chapter 4: Machine Learning Pipeline" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="unsupervised.html" class="btn btn-neutral float-right" title="Chapter 6: Unsupervised Learning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>