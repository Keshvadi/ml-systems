\section*{Use Cases}
\vspace*{-0.1in}
\prob{4} 
When using DNS queries and responses to identify traffic flows for a service,
which of the following pieces of information would you need from the
corresponding DNS traffic? Select all that apply.

\begin{center}
\begin{tabularx}{0.9\textwidth}{X X}
\answercircle{The date and time of each query and response} &
\correctanswercircle{The DNS names corresponding to the service}
\\
\correctanswercircle{The DNS query ID for each query and
response} & \answercircle{The latency of the query and
response}
\end{tabularx}
\end{center}
\eprob

\prob{2} A feature that we explored in the first assignment for
quality of experience estimation was the number of segments per second.
What is a segment?
\\
\answerbox{1}{In the context of video streaming, a segment is a part of the
video that is separately downloadable and playable by the client. DASH breaks
down the entire media content into these
segments, typically a few seconds each, which allows for adaptive streaming by
adjusting the quality of each segment based on the user's current network
conditions and device capabilities.}
\eprob

\prob{2} Given a sequence of packets (e.g., captured from a packet capture
tool like Wireshark), what property or properties of the packets could you use to group
packets into segments?
\\
\answerbox{1}{Packet size turns out to be very useful for grouping packets
into segments. Over the course of a video stream, as content is downloaded,
there are typically periods where there are small (or zero-byte) packets in
between segments that can be useful for identifying segment boundaries.}

\eprob


\section*{Data Acquisition}

\prob{4} 
    Which characteristics of a network traffic trace are used
    to group packets into flows? Select all that apply.
\begin{center}
\begin{tabularx}{0.9\textwidth}{X X}
    \correctanswercircle{Source and destination IP addresses} &
    \correctanswercircle{Source and destination port numbers}
    \\
    \correctanswercircle{Protocol} & \answercircle{Packet size}
    \\
    \answercircle{Time of day} & \answercircle{Packet sequence numbers}
\end{tabularx}
\end{center}
\eprob

\prob{2}
In the context of using machine learning to predict network performance, which
of the following statements best describes active performance measurements?
    Select all that apply.
\begin{center}
    \begin{tabularx}{0.9\textwidth}{X X}
        \correctanswercircle{Sending test packets into the network.} &
        \correctanswercircle{Performing a download.}
        \\
        \answercircle{Capturing network traffic from users.} &
        \answercircle{Monitoring historical network logs.}

    \end{tabularx}
\end{center}
\eprob

\prob{2} Describe one advantage of using active measurements as a way of
gathering features that could be used as input to a machine learning model for
predicting network performance.

\answerbox{1}{Various answers are possible. One advantage is that active
measurements are a direct measurement of the network performance, so no
inference is necessary. They can also be conducted "on demand", at regular
intevals. Finally, active measurements do not pose the same privacy risks or
considerations as passive measurements.} 


\eprob

    \section*{Feature Engineering}

    \prob{2}
    Many machine learning models are now capable of taking ``raw'' data as
    input, such as images, text, or even network traffic traces. However, in
    many cases, it is still useful to perform some preprocessing on the data
    before feeding it into the model. Provide one reason why preprocessing
    inputs to a machine learning model might improve model {\bf efficiency}.
    \\
    \answerbox{1}{Preprocessing the data can reduce the overall size of the
    data, which can lead to faster training times. For example, computing
    derived statistics from raw data can reduce the number of features that
    need to be processed by the model, and can also avoid "representation
    learning", which can sometimes be expensive.}

    \eprob

    \prob{2}
Provide one reason why preprocessing
    inputs to a machine learning model might improve model {\bf accuracy}.
\\  
\answerbox{1}{Models can sometimes pick up on "spurious correlations", or
irrelevant features in the dataset. Preprocessing, particularly when performed
with some domain knowledge, can reduce the likelihood that a model could
incorporate these irrelevant features.}
\eprob


    \if 0
    In class, we looked at some cases where ML models perform sub-optimally
    when
    trained exclusively with raw data and  
    that {\em domain knowledge} is often useful for feature engineering.
    \fi



\section*{Machine Learning Pipelines}

    \prob{2}
In the context of the bias-variance tradeoff, which of the following scenarios
best describes a model with too-high variance? Select all that apply.
\begin{center}
    \begin{tabularx}{0.99\textwidth}{X X}
        \answercircle{Performs poorly on the training data.} &
        \correctanswercircle{Performs well on the training data but poorly on the test data.}
        \\
        \answercircle{Performs well on the training data and well on the test data.} &
        \answercircle{Shows stable performance across different datasets.}
    \end{tabularx}
\end{center}
    \eprob

    \prob{5}
    Your team is building a machine learning model to predict network
    performance. You have collected a dataset of network traces, and you have
    preprocessed the data to extract features. One of the features is
    normalized throughput, which is the ratio of the throughput of a network
    flow to the maximum throughput observed in the dataset.  

    When computing this value for training, do you use:
\begin{center}
    \begin{tabularx}{0.4\textwidth}{X X}
        \correctanswercircle{The training set.} &
        \answercircle{The entire dataset.}
    \end{tabularx}
\end{center}
Briefly explain your answer. 
    \\
    \answerbox{1.25}{Computing statistics over the entire dataset before
    performing a train-test split can lead to data leakage, where information
    from the test set is inadvertently used to train the model. This can lead
    to overly optimistic performance estimates.}

    \eprob

    \section*{Feedback}
    \vspace*{-0.25in}
    \prob{1}
    Interest (1=Boring!; 10=Amazing!):
    \shortanswerbox{0.5}{5}
    Difficulty (1=Too easy; 10=Too hard):
    \shortanswerbox{0.5}{5}
    \eprob
    \prob{1}
    1. One thing you like. 2. One suggestion for improvement:

    \answerbox{0.75}{1. The professor's jokes are so funny. 2. More free food! }
    \eprob


